{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e560ae",
   "metadata": {},
   "source": [
    "Import all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea805bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nibabel numpy scipy matplotlib scikit-image torch torchvision pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0441e9ad",
   "metadata": {},
   "source": [
    "GPU Available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8138e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6b15e",
   "metadata": {},
   "source": [
    "DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc058292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "CSV_PATH = r\"D:/ADNI Data/BETandGroups.csv\" \n",
    "IMG_SIZE = (128, 128, 128)\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 30\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Nifti3DDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_encoder = label_encoder\n",
    "        self.target_shape = IMG_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.loc[idx, \"Ruta\"]\n",
    "        label = self.df.loc[idx, \"Grupo\"]\n",
    "\n",
    "        volume = nib.load(path).get_fdata().astype(np.float32)\n",
    "        zoom_factors = [t / s for t, s in zip(self.target_shape, volume.shape)]\n",
    "        volume = scipy.ndimage.zoom(volume, zoom=zoom_factors, order=3)\n",
    "\n",
    "        volume = (volume - np.mean(volume)) / (np.std(volume) + 1e-8)\n",
    "        volume = np.clip(volume, -3, 3)\n",
    "\n",
    "        volume = torch.tensor(volume).unsqueeze(0) \n",
    "        label = torch.tensor(self.label_encoder.transform([label])[0])\n",
    "        return volume, label\n",
    "\n",
    "# Arquitectura DenseNet3D\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.norm = nn.BatchNorm3d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv3d(in_channels, growth_rate, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(self.relu(self.norm(x)))\n",
    "        return torch.cat([x, out], 1)\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, growth_rate):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(DenseLayer(in_channels + i * growth_rate, growth_rate))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.norm = nn.BatchNorm3d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "        self.pool = nn.AvgPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.relu(self.norm(x)))\n",
    "        return self.pool(x)\n",
    "\n",
    "class DenseNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, block_config, num_classes):\n",
    "        super(DenseNet3D, self).__init__()\n",
    "        num_init_features = 2 * growth_rate\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, num_init_features, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm3d(num_init_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = DenseBlock(num_layers, num_features, growth_rate)\n",
    "            self.features.add_module(f'denseblock{i+1}', block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = Transition(num_features, num_features // 2)\n",
    "                self.features.add_module(f'transition{i+1}', trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        self.features.add_module('norm_final', nn.BatchNorm3d(num_features))\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "#Cargar datos\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['Grupo'])\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, stratify=df['labels'], random_state=42)\n",
    "train_dataset = Nifti3DDataset(df_train, le)\n",
    "val_dataset = Nifti3DDataset(df_val, le)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = DenseNet3D(\n",
    "    in_channels=1,\n",
    "    growth_rate=16,\n",
    "    block_config=(4, 4, 4),\n",
    "    num_classes=len(le.classes_)\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_train = 100 * train_correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1} - Loss: {train_loss:.4f}, Train Acc: {acc_train:.2f}%\")\n",
    "    torch.save(model.state_dict(), \"densenet3d_alzheimer.pth\")\n",
    "    print(\"Modelo guardado como densenet3d_alzheimer.pth\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    acc_val = 100 * val_correct / len(val_dataset)\n",
    "    print(f\"Test Acc: {acc_val:.2f}%\")\n",
    "\n",
    "# ========= GUARDAR =========\n",
    "torch.save(model.state_dict(), \"densenet3d_alzheimer.pth\")\n",
    "print(\"Modelo final guardado como densenet3d_alzheimer.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6766b",
   "metadata": {},
   "source": [
    "Entrenar mas epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b570643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy.ndimage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "CSV_PATH = r\"D:/ADNI Data/BETandGroups.csv\"\n",
    "IMG_SIZE = (128, 128, 128)\n",
    "BATCH_SIZE = 2\n",
    "START_EPOCH = 70\n",
    "END_EPOCH = 80\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Nifti3DDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_encoder = label_encoder\n",
    "        self.target_shape = IMG_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.loc[idx, \"Ruta\"]\n",
    "        label = self.df.loc[idx, \"Grupo\"]\n",
    "\n",
    "        volume = nib.load(path).get_fdata().astype(np.float32)\n",
    "        zoom_factors = [t / s for t, s in zip(self.target_shape, volume.shape)]\n",
    "        volume = scipy.ndimage.zoom(volume, zoom=zoom_factors, order=3)\n",
    "\n",
    "        volume = (volume - np.mean(volume)) / (np.std(volume) + 1e-8)\n",
    "        volume = np.clip(volume, -3, 3)\n",
    "\n",
    "        volume = torch.tensor(volume).unsqueeze(0)\n",
    "        label = torch.tensor(self.label_encoder.transform([label])[0])\n",
    "        return volume, label\n",
    "\n",
    "#Arquitectura DenseNet3D\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.norm = nn.BatchNorm3d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv3d(in_channels, growth_rate, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(self.relu(self.norm(x)))\n",
    "        return torch.cat([x, out], 1)\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, growth_rate):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(DenseLayer(in_channels + i * growth_rate, growth_rate))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.norm = nn.BatchNorm3d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "        self.pool = nn.AvgPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.relu(self.norm(x)))\n",
    "        return self.pool(x)\n",
    "\n",
    "class DenseNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, block_config, num_classes):\n",
    "        super(DenseNet3D, self).__init__()\n",
    "        num_init_features = 2 * growth_rate\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, num_init_features, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm3d(num_init_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = DenseBlock(num_layers, num_features, growth_rate)\n",
    "            self.features.add_module(f'denseblock{i+1}', block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = Transition(num_features, num_features // 2)\n",
    "                self.features.add_module(f'transition{i+1}', trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        self.features.add_module('norm_final', nn.BatchNorm3d(num_features))\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['Grupo'])\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, stratify=df['labels'], random_state=42)\n",
    "train_dataset = Nifti3DDataset(df_train, le)\n",
    "val_dataset = Nifti3DDataset(df_val, le)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = DenseNet3D(\n",
    "    in_channels=1,\n",
    "    growth_rate=16,\n",
    "    block_config=(4, 4, 4),\n",
    "    num_classes=len(le.classes_)\n",
    ").to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(\"densenet3d_alzheimer-extended2.pth\", map_location=DEVICE))\n",
    "print(f\"Modelo cargado desde 'densenet3d_alzheimer-extended2.pth'\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(START_EPOCH, END_EPOCH):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{END_EPOCH}\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_train = 100 * train_correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1} - Loss: {train_loss:.4f}, Train Acc: {acc_train:.2f}%\")\n",
    "\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_val = 100 * val_correct / len(val_dataset)\n",
    "    print(f\"üîç Val Acc: {acc_val:.2f}%\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"densenet3d_alzheimer-extended3.pth\")\n",
    "    print(\"Modelo guardado como densenet3d_alzheimer-extended3.pth\")\n",
    "\n",
    "print(\"Entrenamiento completado hasta la √©poca 70.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
