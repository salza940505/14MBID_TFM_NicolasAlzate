{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e560ae",
   "metadata": {},
   "source": [
    "Import all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea805bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nibabel numpy scipy matplotlib scikit-image torch torchvision pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0441e9ad",
   "metadata": {},
   "source": [
    "GPU Available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8138e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6b15e",
   "metadata": {},
   "source": [
    "AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc058292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "IMG_SIZE = (128, 128, 128)\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 30\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Nifti3DDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_encoder = label_encoder\n",
    "        self.target_shape = IMG_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.loc[idx, \"Ruta\"]\n",
    "        label = self.df.loc[idx, \"Grupo\"]\n",
    "\n",
    "        volume = nib.load(path).get_fdata().astype(np.float32)\n",
    "        zoom_factors = [t / s for t, s in zip(self.target_shape, volume.shape)]\n",
    "        volume = scipy.ndimage.zoom(volume, zoom=zoom_factors, order=3)\n",
    "\n",
    "        volume = (volume - np.mean(volume)) / (np.std(volume) + 1e-8)\n",
    "        volume = np.clip(volume, -3, 3)\n",
    "\n",
    "        volume = torch.tensor(volume).unsqueeze(0)  # [1, D, H, W]\n",
    "        label = torch.tensor(self.label_encoder.transform([label])[0])\n",
    "        return volume, label\n",
    "\n",
    "#Arquitectura AlexNet\n",
    "class AlexNet3D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet3D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv3d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv3d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(r\"D:/ADNI Data/BETandGroups.csv\")\n",
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['Grupo'])\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, stratify=df['labels'], random_state=42)\n",
    "train_dataset = Nifti3DDataset(df_train, le)\n",
    "val_dataset = Nifti3DDataset(df_val, le)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "#Entrenar modelo\n",
    "model = AlexNet3D(num_classes=len(le.classes_)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_train = 100 * train_correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1} - Loss: {train_loss:.4f}, Train Acc: {acc_train:.2f}%\")\n",
    "\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    acc_val = 100 * val_correct / len(val_dataset)\n",
    "    print(f\" Test Acc: {acc_val:.2f}%\")\n",
    "\n",
    "# ========= GUARDAR =========\n",
    "torch.save(model.state_dict(), \"alexnet3d_alzheimer.pth\")\n",
    "print(\"Modelo guardado como alexnet3d_alzheimer.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d1772",
   "metadata": {},
   "source": [
    "AlexNet con modificación porque modelo se estanca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4bb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.ndimage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "CSV_PATH = r\"D:/ADNI Data/BETandGroups.csv\" \n",
    "IMG_SIZE = (128, 128, 128)\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Nifti3DDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_encoder = label_encoder\n",
    "        self.target_shape = IMG_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.loc[idx, \"Ruta\"]\n",
    "        label = self.df.loc[idx, \"Grupo\"]\n",
    "        volume = nib.load(path).get_fdata().astype(np.float32)\n",
    "\n",
    "        zoom_factors = [t / s for t, s in zip(self.target_shape, volume.shape)]\n",
    "        volume = scipy.ndimage.zoom(volume, zoom=zoom_factors, order=3)\n",
    "\n",
    "        volume = (volume - np.mean(volume)) / (np.std(volume) + 1e-8)\n",
    "        volume = np.clip(volume, -3, 3)\n",
    "        volume = torch.tensor(volume).unsqueeze(0)  # [1, D, H, W]\n",
    "        label = torch.tensor(self.label_encoder.transform([label])[0])\n",
    "        return volume, label\n",
    "\n",
    "# ========= MODELO =========\n",
    "class AlexNet3D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet3D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv3d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv3d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "#Cargar datos\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['Grupo'])\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, stratify=df['labels'], random_state=42)\n",
    "\n",
    "train_dataset = Nifti3DDataset(df_train, le)\n",
    "val_dataset = Nifti3DDataset(df_val, le)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "#Entrenar modelo\n",
    "model = AlexNet3D(num_classes=len(le.classes_)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3, cooldown=2, verbose=True, min_lr=1e-7\n",
    ")\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_train = 100 * train_correct / len(train_dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    acc_val = 100 * val_correct / len(val_dataset)\n",
    "\n",
    "    # Ajuste dinámico del learning rate\n",
    "    scheduler.step(acc_val)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Loss: {train_loss:.4f}, Train Acc: {acc_train:.2f}%, Val Acc: {acc_val:.2f}%, LR: {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "    # Guardar el mejor modelo\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        torch.save(model.state_dict(), \"alexnet3d_alzheimer_final.pth\")\n",
    "        print(\"Modelo mejorado guardado\")\n",
    "\n",
    "print(\"Entrenamiento completo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6766b",
   "metadata": {},
   "source": [
    "Entrenar mas epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b570643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy.ndimage\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "CSV_PATH = r\"D:/ADNI Data/BETandGroups.csv\"\n",
    "IMG_SIZE = (128, 128, 128)\n",
    "BATCH_SIZE = 4\n",
    "EXTRA_EPOCHS = 10\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"alexnet3d_alzheimer_extended.pth\"\n",
    "\n",
    "class Nifti3DDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_encoder = label_encoder\n",
    "        self.target_shape = IMG_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.loc[idx, \"Ruta\"]\n",
    "        label = self.df.loc[idx, \"Grupo\"]\n",
    "        volume = nib.load(path).get_fdata().astype(np.float32)\n",
    "\n",
    "        zoom_factors = [t / s for t, s in zip(self.target_shape, volume.shape)]\n",
    "        volume = scipy.ndimage.zoom(volume, zoom=zoom_factors, order=3)\n",
    "\n",
    "        volume = (volume - np.mean(volume)) / (np.std(volume) + 1e-8)\n",
    "        volume = np.clip(volume, -3, 3)\n",
    "        volume = torch.tensor(volume).unsqueeze(0)\n",
    "        label = torch.tensor(self.label_encoder.transform([label])[0])\n",
    "        return volume, label\n",
    "\n",
    "#Architectura AlexNet3D\n",
    "class AlexNet3D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet3D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2),\n",
    "            nn.Conv3d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2),\n",
    "            nn.Conv3d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "#Cargar datos\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['Grupo'])\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, stratify=df['labels'], random_state=42)\n",
    "\n",
    "train_dataset = Nifti3DDataset(df_train, le)\n",
    "val_dataset = Nifti3DDataset(df_val, le)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "#Cargar modelo anterior\n",
    "model = AlexNet3D(num_classes=len(le.classes_)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3, cooldown=2, verbose=True, min_lr=1e-7\n",
    ")\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(EXTRA_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Extra Epoch {epoch+1}/{EXTRA_EPOCHS}\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_train = 100 * train_correct / len(train_dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_val = 100 * val_correct / len(val_dataset)\n",
    "\n",
    "    scheduler.step(acc_val)\n",
    "\n",
    "    print(f\"Extra Epoch {epoch+1} - Loss: {train_loss:.4f}, Train Acc: {acc_train:.2f}%, Val Acc: {acc_val:.2f}%, LR: {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        torch.save(model.state_dict(), \"alexnet3d_alzheimer_extended2.pth\")\n",
    "        print(\"Modelo mejorado guardado\")\n",
    "\n",
    "print(\"Entrenamiento extendido\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
