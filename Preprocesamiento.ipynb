{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b7d174",
   "metadata": {},
   "source": [
    "Init all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716426cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nibabel numpy scipy matplotlib scikit-image torch torchvision pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0eb5c",
   "metadata": {},
   "source": [
    "GPU Available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d61ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4c360",
   "metadata": {},
   "source": [
    "Read Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77575ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rutas = pd.read_csv(\"d:/ADNI Data/directorios2.csv\", header=None)\n",
    "rutas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07804fe",
   "metadata": {},
   "source": [
    "Dicom to Nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa104682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "#Rutas\n",
    "DCM2NIIX_PATH = r\"D:/ADNI Data/dcm2niix_win/dcm2niix.exe\"  \n",
    "OUTPUT_NIFTI_DIR = r\"D:/ADNI Data/Fixed/{0}/volumenes_nifti\" \n",
    "OUTPUT_NPY_DIR = r\"D:/ADNI Data/Fixed/{0}/volumenes_npy\"\n",
    "TARGET_SHAPE = (128, 128, 128)\n",
    "\n",
    "for index, row in rutas.iterrows():\n",
    "    Path_DIR = row[0]\n",
    "    INPUT_DICOM_DIR = r\"D:/ADNI Data/\"+row[0] \n",
    "    \n",
    "    print(INPUT_DICOM_DIR)\n",
    "    OUTPUT_NIFTI_DIR =  OUTPUT_NIFTI_DIR.replace(\"{0}\", Path_DIR)\n",
    "    OUTPUT_NPY_DIR = OUTPUT_NPY_DIR.replace(\"{0}\", Path_DIR)\n",
    "    #Directorios\n",
    "    os.makedirs(OUTPUT_NIFTI_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_NPY_DIR, exist_ok=True)\n",
    "\n",
    "    # Recorrer carpetas\n",
    "    for patient_folder in os.listdir(INPUT_DICOM_DIR):\n",
    "        dcm_folder = os.path.join(INPUT_DICOM_DIR, patient_folder)\n",
    "        if not os.path.isdir(dcm_folder): continue\n",
    "\n",
    "        print(f\"Procesando: {patient_folder}\")\n",
    "\n",
    "        # Convertir\n",
    "        nifti_output_path = os.path.join(OUTPUT_NIFTI_DIR, patient_folder)\n",
    "        os.makedirs(nifti_output_path, exist_ok=True)\n",
    "\n",
    "        subprocess.run([\n",
    "            DCM2NIIX_PATH,\n",
    "            \"-z\", \"y\", \n",
    "            \"-o\", nifti_output_path,\n",
    "            dcm_folder\n",
    "        ])\n",
    "\n",
    "        # Buscar el archivo\n",
    "        nii_files = [f for f in os.listdir(nifti_output_path) if f.endswith('.nii.gz')]\n",
    "        if not nii_files:\n",
    "            print(f\"No se pud convertir ningún NIfTI para {patient_folder}\")\n",
    "            continue\n",
    "\n",
    "        nifti_path = os.path.join(nifti_output_path, nii_files[0])\n",
    "\n",
    "        # Normalizar\n",
    "        img = nib.load(nifti_path)\n",
    "        data = img.get_fdata()\n",
    "        data = (data - np.mean(data)) / np.std(data)\n",
    "\n",
    "        # 3. Resize a 128x128x128\n",
    "        factors = [t / s for t, s in zip(TARGET_SHAPE, data.shape)]\n",
    "        resized = zoom(data, factors)\n",
    "\n",
    "        # 4. Guardar numpy\n",
    "        npy_path = os.path.join(OUTPUT_NPY_DIR, f\"{patient_folder}.npy\")\n",
    "        np.save(npy_path, resized)\n",
    "\n",
    "        print(f\"Guardado: {npy_path}\")\n",
    "\n",
    "    \n",
    "print(\"Conversión Finalizada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d206e57",
   "metadata": {},
   "source": [
    "Instalar HD-BET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/MIC-DKFZ/HD-BET.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d649c",
   "metadata": {},
   "source": [
    "Extracción de cerebro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import HD_BET\n",
    "import torch\n",
    "print(\"HD-BET cargado correctamente ✅\")\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "for index, row in rutas.iterrows():\n",
    "    Path_DIR = os.path.join(r\"D:/ADNI Data/BET\", row[0], \"volumenes_nifti\")\n",
    "    for i in os.scandir(Path_DIR):\n",
    "        for j in os.scandir(i.path):\n",
    "            os.makedirs(i.path.replace(\"volumenes_nifti\", \"volumenes_npy\"), exist_ok=True)\n",
    "            if j.name.endswith(\".nii.gz\"):\n",
    "                print(f\"procesando {j.path}\")\n",
    "                nifti = nib.load(j.path)\n",
    "                img_data = nifti.get_fdata()\n",
    "                OUTPUT_NPY_DIR = j.path.replace(\"volumenes_nifti\", \"volumenes_npy\").replace(\".nii.gz\", \".npy\")\n",
    "                np.save(OUTPUT_NPY_DIR, nifti)\n",
    "print(\"Extracción finalizada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca201b3",
   "metadata": {},
   "source": [
    "Crear CSV con rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff45129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rutaBet = r\"D:\\ADNI Data\\BET\\ADNI\"\n",
    "data = pd.DataFrame(columns=['Ruta', 'ID','Grupo'])\n",
    "rutaAdni = r\"D:/ADNI Data/T1_3D_3T_sagital_4_08_2025.csv\"\n",
    "adniCSV = pd.read_csv(rutaAdni, header= 0, sep=\";\")\n",
    "\n",
    "for i in os.scandir(rutaBet):\n",
    "    for j in os.scandir(i.path):\n",
    "        for k in os.scandir(j.path):\n",
    "            aux = os.path.join(k.path, \"volumenes_nifti\")\n",
    "            for l in os.scandir(aux):\n",
    "                IDAdni = l.name.split(\"\\\\\")[-1]\n",
    "                for m in os.scandir(l.path):\n",
    "                    data = pd.concat([pd.DataFrame([[m.path,IDAdni,adniCSV[adniCSV['Image Data ID'] == IDAdni]['Group'].values[0]]], columns=data.columns), data], ignore_index=True)\n",
    "                \n",
    "\n",
    "data.to_csv(r\"D:/ADNI Data/BETandGroups.csv\", index=False)\n",
    "\n",
    "CNdf = data[data['Grupo'] == 'CN']\n",
    "MCIdf = data[data['Grupo'] == 'MCI']\n",
    "ADdf = data[data['Grupo'] == 'AD']\n",
    "\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size=0.25, random_state=42, stratify=data['Grupo'])\n",
    "CNdf_train = df_train[df_train['Grupo'] == 'CN']\n",
    "CNdf_test = df_test[df_test['Grupo'] == 'CN']   \n",
    "MCIdf_train = df_train[df_train['Grupo'] == 'MCI']\n",
    "MCIdf_test = df_test[df_test['Grupo'] == 'MCI']\n",
    "ADdf_train = df_train[df_train['Grupo'] == 'AD']\n",
    "ADdf_test = df_test[df_test['Grupo'] == 'AD']\n",
    "\n",
    "print(\"CN Total:\", len(CNdf),\"CN train:\", len(CNdf_train),\"CN test:\", len(CNdf_test)) \n",
    "print(\"MCI Total:\", len(MCIdf),\"MCI train:\", len(MCIdf_train),\"MCI test:\", len(MCIdf_test)) \n",
    "print(\"AD Total:\", len(ADdf),\"AD train:\", len(ADdf_train),\"AD test:\", len(ADdf_test))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
