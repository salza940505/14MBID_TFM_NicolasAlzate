{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e560ae",
   "metadata": {},
   "source": [
    "Import all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea805bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nibabel numpy scipy matplotlib scikit-image torch torchvision pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0441e9ad",
   "metadata": {},
   "source": [
    "GPU Available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8138e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6b15e",
   "metadata": {},
   "source": [
    "AlzeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc058292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "TARGET_SHAPE = (128, 128, 128)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class NiftiDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.loc[idx, \"Ruta\"]\n",
    "        label = self.df.loc[idx, \"Grupo\"]\n",
    "\n",
    "        # Cargar\n",
    "        img = nib.load(path)\n",
    "        volume = img.get_fdata().astype(np.float32)\n",
    "\n",
    "        # Normalización\n",
    "        volume = (volume - np.mean(volume)) / (np.std(volume) + 1e-8)\n",
    "\n",
    "        # Resize \n",
    "        volume = self.resize_volume(volume, TARGET_SHAPE)\n",
    "        volume = np.expand_dims(volume, axis=0)\n",
    "\n",
    "        return torch.tensor(volume), torch.tensor(self.label_encoder.transform([label])[0])\n",
    "\n",
    "    def resize_volume(self, volume, target_shape):\n",
    "        volume = torch.tensor(volume).unsqueeze(0).unsqueeze(0)  # [1,1,D,H,W]\n",
    "        volume_resized = F.interpolate(volume, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
    "        return volume_resized.squeeze().numpy()\n",
    "\n",
    "#Arquitectura AlzeNet3D\n",
    "class AlzeNet3D(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(AlzeNet3D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 16 * 16 * 16, 128), nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "#Leer Datos\n",
    "df = pd.read_csv(r\"D:/ADNI Data/BETandGroups.csv\")\n",
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['Grupo'])  # Codificar grupos\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, stratify=df['labels'], random_state=42)\n",
    "\n",
    "train_dataset = NiftiDataset(df_train, le)\n",
    "val_dataset = NiftiDataset(df_val, le)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Entrenamiento\n",
    "model = AlzeNet3D(num_classes=len(le.classes_)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "\n",
    "    acc_train = 100 * train_correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1} - Loss: {train_loss:.4f}, Train Acc: {acc_train:.2f}%\")\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "    acc_val = 100 * val_correct / len(val_dataset)\n",
    "    print(f\"Test Acc: {acc_val:.2f}%\")\n",
    "\n",
    "# ========== GUARDAR ==========\n",
    "torch.save(model.state_dict(), \"alzenet3d_nifti.pth\")\n",
    "print(\"Modelo guardado como alzenet3d_nifti.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
