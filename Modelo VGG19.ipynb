{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e560ae",
   "metadata": {},
   "source": [
    "Import all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea805bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nibabel numpy scipy matplotlib scikit-image torch torchvision pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0441e9ad",
   "metadata": {},
   "source": [
    "GPU Available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8138e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6b15e",
   "metadata": {},
   "source": [
    "VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc058292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# ========== CONFIGURACI√ìN ==========\n",
    "CSV_PATH = r\"D:/ADNI Data/BETandGroups.csv\"\n",
    "IMG_SIZE = (128, 128, 128)\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Optimizaci√≥n GPU\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "# ========== DATASET ==========\n",
    "class Nifti3DDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_encoder = label_encoder\n",
    "        self.target_shape = IMG_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.loc[idx, \"Ruta\"]\n",
    "        label = self.df.loc[idx, \"Grupo\"]\n",
    "\n",
    "        volume = nib.load(path).get_fdata().astype(np.float32)\n",
    "        zoom_factors = [t / c for t, c in zip(self.target_shape, volume.shape)]\n",
    "        volume = scipy.ndimage.zoom(volume, zoom=zoom_factors, order=3)\n",
    "\n",
    "        volume = (volume - np.mean(volume)) / (np.std(volume) + 1e-8)\n",
    "        volume = np.clip(volume, -3, 3)\n",
    "\n",
    "        volume = torch.tensor(volume).unsqueeze(0)\n",
    "        label = torch.tensor(self.label_encoder.transform([label])[0])\n",
    "\n",
    "        return volume, label\n",
    "\n",
    "# ========== MODELO VGG19 3D ==========\n",
    "class VGG19_3D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG19_3D, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels, num_convs):\n",
    "            layers = []\n",
    "            for _ in range(num_convs):\n",
    "                layers.append(nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "                layers.append(nn.ReLU(inplace=True))\n",
    "                in_channels = out_channels\n",
    "            layers.append(nn.MaxPool3d(kernel_size=2, stride=2))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            conv_block(1, 64, 2),\n",
    "            conv_block(64, 128, 2),\n",
    "            conv_block(128, 256, 4),\n",
    "            conv_block(256, 512, 4),\n",
    "            conv_block(512, 512, 4),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 4 * 4 * 4, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ========== CARGA DE DATOS ==========\n",
    "# Aseg√∫rate de tener tu DataFrame \"data\" cargado\n",
    "# df = pd.read_csv(\"rutas.csv\") o como sea que lo tengas\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['Grupo'])\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, stratify=df['labels'], random_state=42)\n",
    "\n",
    "train_dataset = Nifti3DDataset(df_train, le)\n",
    "val_dataset = Nifti3DDataset(df_val, le)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# ========== MODELO Y ENTRENAMIENTO ==========\n",
    "model = VGG19_3D(num_classes=len(le.classes_)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(r\"D:\\ADNI Data\\vgg19_3d_alzheimer_reentrenado.pth\"))  # <-- IMPORTAR MODELO\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-8, verbose=True)\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for inputs, labels in loop:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_train = 100 * train_correct / len(train_dataset)\n",
    "    print(f\"‚úÖ Epoch {epoch+1} - Loss: {train_loss:.4f}, Train Acc: {acc_train:.2f}%\")\n",
    "\n",
    "    # Validaci√≥n\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_val = 100 * val_correct / len(val_dataset)\n",
    "    print(f\"üîç Val Acc: {acc_val:.2f}%\")\n",
    "\n",
    "    torch.cuda.empty_cache()  # limpiar memoria en cada epoch\n",
    "\n",
    "# ========== GUARDAR NUEVO MODELO ==========\n",
    "torch.save(model.state_dict(), \"vgg19_3d_alzheimer_reentrenado2.pth\")\n",
    "print(\"üì¶ Modelo reentrenado y guardado como vgg19_3d_alzheimer_reentrenado2.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6766b",
   "metadata": {},
   "source": [
    "Entrenar mas epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b570643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "CSV_PATH = r\"D:/ADNI Data/BETandGroups.csv\"\n",
    "IMG_SIZE = (128, 128, 128)\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 50\n",
    "LR = 1e-5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Nifti3DDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_encoder = label_encoder\n",
    "        self.target_shape = IMG_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.loc[idx, \"Ruta\"]\n",
    "        label = self.df.loc[idx, \"Grupo\"]\n",
    "\n",
    "        volume = nib.load(path).get_fdata().astype(np.float32)\n",
    "        zoom_factors = [t / s for t, s in zip(self.target_shape, volume.shape)]\n",
    "        volume = scipy.ndimage.zoom(volume, zoom=zoom_factors, order=3)\n",
    "\n",
    "        volume = (volume - np.mean(volume)) / (np.std(volume) + 1e-8)\n",
    "        volume = np.clip(volume, -3, 3)\n",
    "\n",
    "        volume = torch.tensor(volume).unsqueeze(0) \n",
    "        label = torch.tensor(self.label_encoder.transform([label])[0])\n",
    "        return volume, label\n",
    "\n",
    "#Arquitectura VGG16\n",
    "class VGG3D(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(VGG3D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.Conv3d(128, 128, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv3d(128, 256, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv3d(256, 512, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "#Cargar Datos\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['Grupo'])\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, stratify=df['labels'], random_state=42)\n",
    "train_dataset = Nifti3DDataset(df_train, le)\n",
    "val_dataset = Nifti3DDataset(df_val, le)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "#Entrenar el modelo\n",
    "model = VGG3D(num_classes=len(le.classes_)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-8, verbose=True)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc_train = 100 * train_correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1} - Loss: {train_loss:.4f}, Train Acc: {acc_train:.2f}%\")\n",
    "\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    acc_val = 100 * val_correct / len(val_dataset)\n",
    "    print(f\"Test Acc: {acc_val:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), \"vgg16_3d_alzheimer3.pth\")\n",
    "print(\"Modelo guardado como vgg16_3d_alzheimer3.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
